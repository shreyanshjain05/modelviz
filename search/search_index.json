{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"modelviz","text":"<p>Framework-agnostic neural network architecture visualization for Jupyter notebooks.</p> <p>See README.md for documentation.</p>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for modelviz.</p>"},{"location":"api/#main-functions","title":"Main Functions","text":""},{"location":"api/#visualize","title":"<code>visualize()</code>","text":"<p>Generate a 2D Graphviz diagram of a neural network.</p> <pre><code>def visualize(\n    model: Any,\n    input_shape: Optional[tuple[int, ...]] = None,\n    framework: Literal[\"auto\", \"pytorch\", \"tensorflow\"] = \"auto\",\n    show_shapes: bool = True,\n    show_params: bool = True,\n    group_blocks: bool = True,\n    save_path: Optional[str] = None,\n    title: Optional[str] = None,\n) -&gt; graphviz.Digraph\n</code></pre>"},{"location":"api/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>model</code> <code>Any</code> required PyTorch <code>nn.Module</code> or Keras <code>Model</code> <code>input_shape</code> <code>tuple[int, ...]</code> <code>None</code> Input tensor shape. Required for PyTorch <code>framework</code> <code>str</code> <code>\"auto\"</code> Framework: <code>\"auto\"</code>, <code>\"pytorch\"</code>, <code>\"tensorflow\"</code> <code>show_shapes</code> <code>bool</code> <code>True</code> Display output tensor shapes <code>show_params</code> <code>bool</code> <code>True</code> Display parameter counts <code>group_blocks</code> <code>bool</code> <code>True</code> Merge common patterns (Conv+ReLU) <code>save_path</code> <code>str</code> <code>None</code> File path to save (<code>.png</code>, <code>.svg</code>, <code>.pdf</code>) <code>title</code> <code>str</code> <code>None</code> Diagram title"},{"location":"api/#returns","title":"Returns","text":"<p><code>graphviz.Digraph</code> \u2014 Graphviz Digraph object that renders inline in notebooks.</p>"},{"location":"api/#example","title":"Example","text":"<pre><code>from modelviz import visualize\nimport torch.nn as nn\n\nmodel = nn.Sequential(nn.Linear(10, 5), nn.ReLU())\ngraph = visualize(model, input_shape=(1, 10), title=\"MLP\")\n</code></pre>"},{"location":"api/#visualize_threejs","title":"<code>visualize_threejs()</code>","text":"<p>Generate an interactive 3D Three.js visualization.</p> <pre><code>def visualize_threejs(\n    model: Any,\n    input_shape: Optional[tuple[int, ...]] = None,\n    framework: Literal[\"auto\", \"pytorch\", \"tensorflow\"] = \"auto\",\n    show_shapes: bool = True,\n    show_params: bool = True,\n    group_blocks: bool = True,\n    save_path: Optional[str] = None,\n    title: Optional[str] = None,\n) -&gt; str\n</code></pre>"},{"location":"api/#parameters_1","title":"Parameters","text":"Parameter Type Default Description <code>model</code> <code>Any</code> required PyTorch <code>nn.Module</code> or Keras <code>Model</code> <code>input_shape</code> <code>tuple[int, ...]</code> <code>None</code> Input tensor shape. Required for PyTorch <code>framework</code> <code>str</code> <code>\"auto\"</code> Framework: <code>\"auto\"</code>, <code>\"pytorch\"</code>, <code>\"tensorflow\"</code> <code>show_shapes</code> <code>bool</code> <code>True</code> Display shapes in labels <code>show_params</code> <code>bool</code> <code>True</code> Display params in tooltips <code>group_blocks</code> <code>bool</code> <code>True</code> Merge common patterns <code>save_path</code> <code>str</code> <code>None</code> File path to save (<code>.html</code>) <code>title</code> <code>str</code> <code>None</code> Visualization title"},{"location":"api/#returns_1","title":"Returns","text":"<p><code>str</code> \u2014 Complete HTML string with embedded Three.js visualization.</p>"},{"location":"api/#example_1","title":"Example","text":"<pre><code>from modelviz import visualize_threejs\n\nhtml = visualize_threejs(\n    model,\n    input_shape=(1, 3, 224, 224),\n    save_path=\"model.html\",\n    title=\"CNN 3D View\"\n)\n</code></pre>"},{"location":"api/#visualize_3d","title":"<code>visualize_3d()</code>","text":"<p>Generate a Plotly 3D visualization (simpler alternative to Three.js).</p> <pre><code>def visualize_3d(\n    model: Any,\n    input_shape: Optional[tuple[int, ...]] = None,\n    framework: Literal[\"auto\", \"pytorch\", \"tensorflow\"] = \"auto\",\n    show_shapes: bool = True,\n    show_params: bool = True,\n    group_blocks: bool = True,\n    layout: Literal[\"tower\", \"spiral\", \"grid\"] = \"tower\",\n    save_path: Optional[str] = None,\n    title: Optional[str] = None,\n) -&gt; plotly.graph_objects.Figure\n</code></pre>"},{"location":"api/#parameters_2","title":"Parameters","text":"<p>Same as <code>visualize_threejs()</code> plus:</p> Parameter Type Default Description <code>layout</code> <code>str</code> <code>\"tower\"</code> 3D layout: <code>\"tower\"</code>, <code>\"spiral\"</code>, <code>\"grid\"</code>"},{"location":"api/#returns_2","title":"Returns","text":"<p><code>plotly.graph_objects.Figure</code> \u2014 Interactive Plotly figure.</p>"},{"location":"api/#data-classes","title":"Data Classes","text":""},{"location":"api/#layernode","title":"<code>LayerNode</code>","text":"<p>Represents a single layer in the neural network.</p> <pre><code>@dataclass\nclass LayerNode:\n    id: int                                    # Unique layer ID\n    name: str                                  # Full layer name (e.g., \"features.conv1\")\n    type: str                                  # Layer type (e.g., \"Conv2d\")\n    input_shape: Optional[tuple[int, ...]]     # Input tensor shape\n    output_shape: Optional[tuple[int, ...]]    # Output tensor shape\n    params: int                                # Number of trainable parameters\n    is_grouped: bool = False                   # Whether merged with adjacent layers\n\n    @property\n    def display_type(self) -&gt; str:            # For grouped: \"Conv2d + ReLU\"\n\n    @property\n    def formatted_output_shape(self) -&gt; str:  # \"(1, 64, 28, 28)\"\n\n    @property\n    def formatted_params(self) -&gt; str:        # \"1.2M\" or \"4.5K\"\n</code></pre>"},{"location":"api/#utility-functions","title":"Utility Functions","text":""},{"location":"api/#detect_framework","title":"<code>detect_framework()</code>","text":"<p>Detect whether a model is PyTorch or TensorFlow.</p> <pre><code>from modelviz.utils import detect_framework\n\nframework = detect_framework(model)  # Returns \"pytorch\" or \"tensorflow\"\n</code></pre>"},{"location":"api/#group_layers","title":"<code>group_layers()</code>","text":"<p>Merge common layer patterns.</p> <pre><code>from modelviz.utils import group_layers\n\nnodes = [...]  # List of LayerNode\ngrouped = group_layers(nodes)  # Returns grouped LayerNode list\n</code></pre>"},{"location":"api/#trace_pytorch_graph","title":"<code>trace_pytorch_graph()</code>","text":"<p>Trace a PyTorch model with skip connections using torch.fx.</p> <pre><code>from modelviz.parsers import trace_pytorch_graph\n\nnodes, edges = trace_pytorch_graph(model, input_shape)\n# edges include edge_type: 'sequential', 'residual', 'concat'\n</code></pre>"},{"location":"api/#has_skip_connections","title":"<code>has_skip_connections()</code>","text":"<p>Check if a model has skip/residual connections.</p> <pre><code>from modelviz.parsers import has_skip_connections\n\nif has_skip_connections(model):\n    print(\"Model has skip connections!\")\n</code></pre>"},{"location":"api/#exceptions","title":"Exceptions","text":""},{"location":"api/#visualizationerror","title":"<code>VisualizationError</code>","text":"<p>Base exception for all modelviz errors.</p>"},{"location":"api/#inputshaperequirederror","title":"<code>InputShapeRequiredError</code>","text":"<p>Raised when <code>input_shape</code> is required but not provided (PyTorch models).</p>"},{"location":"api/#unsupportedframeworkerror","title":"<code>UnsupportedFrameworkError</code>","text":"<p>Raised when model type is not supported.</p>"},{"location":"examples/","title":"Examples","text":"<p>Complete code examples for common modelviz use cases.</p>"},{"location":"examples/#pytorch-examples","title":"PyTorch Examples","text":""},{"location":"examples/#simple-mlp","title":"Simple MLP","text":"<pre><code>import torch.nn as nn\nfrom modelviz import visualize, visualize_threejs\n\nmodel = nn.Sequential(\n    nn.Linear(784, 512),\n    nn.ReLU(),\n    nn.Linear(512, 256),\n    nn.ReLU(),\n    nn.Linear(256, 10)\n)\n\n# 2D visualization\nvisualize(model, input_shape=(1, 784), save_path=\"mlp.png\")\n\n# 3D visualization\nvisualize_threejs(model, input_shape=(1, 784), save_path=\"mlp_3d.html\")\n</code></pre>"},{"location":"examples/#convolutional-neural-network","title":"Convolutional Neural Network","text":"<pre><code>import torch.nn as nn\nfrom modelviz import visualize_threejs\n\nclass CNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(256 * 4 * 4, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(1024, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\nmodel = CNN(num_classes=10)\nvisualize_threejs(\n    model,\n    input_shape=(1, 3, 32, 32),\n    title=\"CIFAR-10 CNN\",\n    save_path=\"cnn_3d.html\"\n)\n</code></pre>"},{"location":"examples/#resnet-style-block","title":"ResNet-style Block","text":"<pre><code>import torch.nn as nn\nfrom modelviz import visualize\n\nclass ResBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.relu = nn.ReLU()\n        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(channels)\n\n    def forward(self, x):\n        identity = x\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += identity\n        return self.relu(out)\n\nmodel = ResBlock(64)\nvisualize(model, input_shape=(1, 64, 32, 32), title=\"ResNet Block\")\n</code></pre>"},{"location":"examples/#rnn-lstm","title":"RNN / LSTM","text":"<pre><code>import torch.nn as nn\nfrom modelviz import visualize_threejs\n\nclass LSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        _, (h_n, _) = self.lstm(x)\n        return self.fc(h_n[-1])\n\nmodel = LSTMClassifier(vocab_size=10000, embed_dim=128, hidden_dim=256, num_classes=5)\nvisualize_threejs(model, input_shape=(1, 100), title=\"LSTM Classifier\")\n</code></pre>"},{"location":"examples/#tensorflowkeras-examples","title":"TensorFlow/Keras Examples","text":""},{"location":"examples/#keras-sequential","title":"Keras Sequential","text":"<pre><code>import tensorflow as tf\nfrom modelviz import visualize\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(28, 28, 1)),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nvisualize(model, save_path=\"keras_cnn.svg\")\n</code></pre>"},{"location":"examples/#keras-functional-api","title":"Keras Functional API","text":"<pre><code>import tensorflow as tf\nfrom modelviz import visualize_threejs\n\ninputs = tf.keras.Input(shape=(224, 224, 3))\nx = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.MaxPooling2D()(x)\nx = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(256, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.5)(x)\noutputs = tf.keras.layers.Dense(1000, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\nvisualize_threejs(model, title=\"ImageNet Classifier\", save_path=\"imagenet_3d.html\")\n</code></pre>"},{"location":"examples/#saving-options","title":"Saving Options","text":""},{"location":"examples/#png-raster","title":"PNG (raster)","text":"<pre><code>visualize(model, input_shape, save_path=\"model.png\")\n</code></pre>"},{"location":"examples/#svg-vector","title":"SVG (vector)","text":"<pre><code>visualize(model, input_shape, save_path=\"model.svg\")\n</code></pre>"},{"location":"examples/#pdf","title":"PDF","text":"<pre><code>visualize(model, input_shape, save_path=\"model.pdf\")\n</code></pre>"},{"location":"examples/#interactive-html-threejs","title":"Interactive HTML (Three.js)","text":"<pre><code>visualize_threejs(model, input_shape, save_path=\"model.html\")\n</code></pre>"},{"location":"examples/#customization","title":"Customization","text":""},{"location":"examples/#disable-grouping","title":"Disable grouping","text":"<pre><code>visualize(model, input_shape, group_blocks=False)\n</code></pre>"},{"location":"examples/#hide-shapes","title":"Hide shapes","text":"<pre><code>visualize(model, input_shape, show_shapes=False)\n</code></pre>"},{"location":"examples/#hide-parameters","title":"Hide parameters","text":"<pre><code>visualize(model, input_shape, show_params=False)\n</code></pre>"},{"location":"examples/#add-title","title":"Add title","text":"<pre><code>visualize(model, input_shape, title=\"My Amazing Model\")\n</code></pre>"},{"location":"getting-started/","title":"Getting Started with modelviz","text":"<p>This guide will help you install modelviz and create your first neural network visualization.</p>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>pip package manager</li> </ul>"},{"location":"getting-started/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install modelviz\n</code></pre>"},{"location":"getting-started/#install-with-framework-support","title":"Install with framework support","text":"<pre><code># For PyTorch models\npip install modelviz[torch]\n\n# For TensorFlow/Keras models\npip install modelviz[tf]\n\n# For both frameworks\npip install modelviz[torch,tf]\n</code></pre>"},{"location":"getting-started/#system-dependency-for-2d-diagrams-only","title":"System dependency (for 2D diagrams only)","text":"<p>For Graphviz 2D diagrams, install the system package:</p> <pre><code># macOS\nbrew install graphviz\n\n# Ubuntu/Debian\nsudo apt-get install graphviz\n\n# Windows\nconda install -c conda-forge graphviz\n</code></pre> <p>Note: Three.js 3D visualizations work without any system dependencies.</p>"},{"location":"getting-started/#your-first-visualization","title":"Your First Visualization","text":""},{"location":"getting-started/#1-create-a-simple-pytorch-model","title":"1. Create a simple PyTorch model","text":"<pre><code>import torch.nn as nn\n\nmodel = nn.Sequential(\n    nn.Linear(784, 256),\n    nn.ReLU(),\n    nn.Linear(256, 128),\n    nn.ReLU(),\n    nn.Linear(128, 10)\n)\n</code></pre>"},{"location":"getting-started/#2-generate-a-2d-diagram","title":"2. Generate a 2D diagram","text":"<pre><code>from modelviz import visualize\n\n# Renders inline in Jupyter notebooks\ngraph = visualize(model, input_shape=(1, 784))\n\n# Save to file\nvisualize(model, input_shape=(1, 784), save_path=\"my_model.png\")\n</code></pre>"},{"location":"getting-started/#3-generate-an-interactive-3d-visualization","title":"3. Generate an interactive 3D visualization","text":"<pre><code>from modelviz import visualize_threejs\n\n# Creates an HTML file you can open in any browser\nvisualize_threejs(\n    model, \n    input_shape=(1, 784), \n    save_path=\"my_model_3d.html\"\n)\n</code></pre>"},{"location":"getting-started/#understanding-the-output","title":"Understanding the Output","text":""},{"location":"getting-started/#2d-diagrams","title":"2D Diagrams","text":"<p>The 2D Graphviz output shows: - Layer type as the node label - Output shape below the layer name - Parameter count at the bottom - Color coding by layer type</p>"},{"location":"getting-started/#3d-visualizations","title":"3D Visualizations","text":"<p>The Three.js 3D output includes: - Distinct shapes for each layer type (boxes, spheres, planes, etc.) - Floating labels above each shape - Animated particles showing data flow - Interactive controls (rotate, zoom, pan)</p>"},{"location":"getting-started/#layer-grouping","title":"Layer Grouping","text":"<p>By default, modelviz groups common layer patterns:</p> Pattern Grouped As Conv2d \u2192 ReLU Conv2d + ReLU Conv2d \u2192 BatchNorm2d \u2192 ReLU Conv2d + BatchNorm2d + ReLU Linear \u2192 ReLU Linear + ReLU <p>This creates cleaner, more readable diagrams. Disable with:</p> <pre><code>visualize(model, input_shape, group_blocks=False)\n</code></pre>"},{"location":"getting-started/#tensorflowkeras-models","title":"TensorFlow/Keras Models","text":"<p>Keras models don't require <code>input_shape</code> since they're already built:</p> <pre><code>import tensorflow as tf\nfrom modelviz import visualize\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\n# No input_shape needed!\nvisualize(model, save_path=\"keras_model.svg\")\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>See API Reference for detailed function documentation</li> <li>Check out Examples for more complex models</li> <li>Learn about 3D Visualization features</li> </ul>"},{"location":"threejs/","title":"Three.js 3D Visualization","text":"<p>modelviz includes a stunning Three.js-based 3D renderer that creates interactive visualizations of neural network architectures.</p>"},{"location":"threejs/#overview","title":"Overview","text":"<p>The Three.js renderer creates self-contained HTML files with: - Distinct 3D shapes for each layer type - Horizontal layout with data flowing left to right - Text labels above each layer - Animated particles showing data flow - Interactive controls for exploration</p>"},{"location":"threejs/#usage","title":"Usage","text":"<pre><code>from modelviz import visualize_threejs\n\nhtml = visualize_threejs(\n    model,\n    input_shape=(1, 3, 224, 224),\n    title=\"My Network\",\n    save_path=\"network.html\"\n)\n\n# Open network.html in any web browser\n</code></pre>"},{"location":"threejs/#layer-shapes","title":"Layer Shapes","text":"<p>Each layer type has a semantically meaningful 3D representation:</p> Layer Type Shape Rationale Conv2d 3D Box Feature maps are 3D volumes (Channels \u00d7 Height \u00d7 Width) Linear/Dense Flat Plane Weight matrix is 2D (input features \u00d7 output features) Pooling Small Cube Reduces spatial dimensions \u2192 smaller representation Activation Glowing Sphere Element-wise operation applied uniformly BatchNorm Thin Slab Normalizes across batch, \"flattens\" distribution Flatten Cone Funnels multi-dimensional data into 1D vector Dropout Wireframe Cube Sparse/transparent = random neurons \"dropped\" RNN/LSTM Cylinder Circular shape suggests recurrent/cyclical flow Attention Octahedron Multi-faceted for multi-head attention patterns"},{"location":"threejs/#color-scheme","title":"Color Scheme","text":"Layer Type Color Hex Code Convolution Indigo <code>#6366f1</code> Linear/Dense Purple <code>#8b5cf6</code> Pooling Cyan <code>#06b6d4</code> Normalization Emerald <code>#10b981</code> Activation Amber <code>#f59e0b</code> Dropout Red <code>#ef4444</code> Flatten Pink <code>#ec4899</code> Embedding Lime <code>#84cc16</code> RNN/LSTM Teal <code>#14b8a6</code> Attention Orange <code>#f97316</code>"},{"location":"threejs/#interactive-controls","title":"Interactive Controls","text":"Action Mouse/Keyboard Rotate Click and drag Zoom Scroll wheel Pan Shift + drag Layer details Hover over shape"},{"location":"threejs/#labels","title":"Labels","text":"<p>Each 3D shape has a floating label showing: - Layer type (e.g., \"Conv2d + BatchNorm2d + ReLU\") - Output dimensions (e.g., \"16\u00d716\")</p> <p>Labels always face the camera for readability.</p>"},{"location":"threejs/#tooltips","title":"Tooltips","text":"<p>Hovering over any layer shows detailed information: - Full layer name - Complete output shape - Parameter count - Whether grouped with other layers</p>"},{"location":"threejs/#animations","title":"Animations","text":"<ul> <li>Data flow particles: Blue spheres animate along connection lines</li> <li>Activation rotation: Spheres slowly rotate</li> <li>Attention oscillation: Octahedrons gently rotate</li> </ul>"},{"location":"threejs/#examples","title":"Examples","text":""},{"location":"threejs/#simple-mlp","title":"Simple MLP","text":"<pre><code>import torch.nn as nn\nfrom modelviz import visualize_threejs\n\nmodel = nn.Sequential(\n    nn.Linear(784, 512),\n    nn.ReLU(),\n    nn.Dropout(0.2),\n    nn.Linear(512, 256),\n    nn.ReLU(),\n    nn.Linear(256, 10)\n)\n\nvisualize_threejs(model, input_shape=(1, 784), save_path=\"mlp.html\")\n</code></pre>"},{"location":"threejs/#cnn","title":"CNN","text":"<pre><code>model = nn.Sequential(\n    nn.Conv2d(3, 64, 3, padding=1),\n    nn.BatchNorm2d(64),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Conv2d(64, 128, 3, padding=1),\n    nn.BatchNorm2d(128),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Flatten(),\n    nn.Linear(128 * 8 * 8, 10)\n)\n\nvisualize_threejs(model, input_shape=(1, 3, 32, 32), save_path=\"cnn.html\")\n</code></pre>"},{"location":"threejs/#without-grouping","title":"Without grouping","text":"<p>To see all individual layers:</p> <pre><code>visualize_threejs(\n    model,\n    input_shape=(1, 3, 32, 32),\n    group_blocks=False,  # Show Conv, BatchNorm, ReLU separately\n    save_path=\"cnn_detailed.html\"\n)\n</code></pre>"},{"location":"threejs/#technical-details","title":"Technical Details","text":"<ul> <li>Renderer: Three.js r160 with WebGL</li> <li>Labels: CSS2DRenderer for crisp text</li> <li>Self-contained: No external dependencies (CDN imports)</li> <li>File size: ~25-35 KB per visualization</li> <li>Browser support: Chrome, Firefox, Safari, Edge (modern versions)</li> </ul>"}]}